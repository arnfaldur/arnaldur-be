#+title: Notes
* The idea
At first I was trying to decide on an opening repertoire for myself.
I had the idea to pick some opening line, looking at the most common opponent moves and using an engine to inform the best refutation.
After doing this up to a certain depth I hoped that the resulting game tree would be manageable enough in size so that I could remember most of it.
At least enough to give me an advantage against less prepared opponents.

I did this manually for a while which was pretty fun as I found some interesting lines.
It was however very tedious and repetitive. I had the engine find the best move(s),
added them as variations and then referenced the lichess analysis board to find the most common answers and added them as variations as well.

This method was very time consuming which meant that the analysis couldn't be as in depth.

- I Want to find transpositions to minimize the size of the DAG by occsasionally picking a non best move according to the engine, as long as it isn't too bad according to the engine, such that I can increase the depth of the repertoire.

I tried to use some chess software like scid and lucaschess but they both fell a bit short of what I wanted to do.
Therefore I decided to get and process the entire public lichess games database, which seemed like an interesting challenge in itself.
* First steps

python xkcd: https://xkcd.com/353/
Reading a few games was simple using python.
January of 2023 has 103,178,407 games and is a 33.5 GB Zstandard compressed PGN file.

The file is too large to decompress in RAM so reading through it by streaming needs to be done.
Fortunately, as most things are, getting a minimal working example working was easy to do in python.
#+begin_src python
import zstandard as zstd
with open("../lichess-database/lichess_db_standard_rated_2023-01.pgn.zst", "rb") as f:
    dctx = zstd.ZstdDecompressor()
    with dctx.stream_reader(f) as reader:
        print(reader.read(8000).decode("utf-8"))
#+end_src

After a short detour into utf decoding issues I had this working prototype.
#+begin_src python
import io
from collections import defaultdict
import json

import zstandard as zstd
import chess.pgn
from tqdm import tqdm


def get_trimmed_fen(move):
    return (
        move.board().fen()
        # remove the fullmove counter to allow delayed transpositions
        .removesuffix(str(move.board().fullmove_number))[:-1]
        # remove the threefold repetition counter
        # .removesuffix(str(move.board().halfmove_clock))[:-1] # or not
    )


result = defaultdict(lambda: defaultdict(int))
with io.TextIOWrapper(
    zstd.ZstdDecompressor().stream_reader(
        open("../lichess-database/lichess_db_standard_rated_2023-01.pgn.zst", "rb")
    ),
    encoding="utf-8",
) as reader:
    try:
        for _ in tqdm(range(int(1.1e9))):
            game = chess.pgn.read_game(reader)
            last_move = get_trimmed_fen(game)
            for move in game.mainline():
                # count one visit
                result[last_move][move.san()] += 1
                last_move = get_trimmed_fen(move)
    except KeyboardInterrupt:
        print("interrupted")

with open("test-book.json", "w") as bookfile:
    bookfile.write(json.dumps(result))
#+end_src

** Sidenote
It is common to speak of the graph of all possible moves in discrete games as a game tree.
In chess, the graph is technically a DAG ([[https://en.wikipedia.org/wiki/Directed_acyclic_graph][Directed acyclic graph]]).
Maybe irrelevant: (A game tree is not the same as a game DAG and I am being specific when I speak of one instead of the other.)

this should be a footnote: (as some openings can transpose into others and many different games can end in the same endgame positions. The graph is acyclic because every move can either change the board to a new position unlike all previous positions or increase the threefold repetition counter.
If it wasn't acyclic, there would be a way to repeat the same positions forever without the game ending legally.)

** continued
The python code generates a game DAG which counts the number of visits of each encountered node and stores it as a json file.
It is terribly slow, averaging around 30 games/sec. At that speed it would take around 40 days to process January.

As this is mostly about studying openings I tried a simple trick to consider only common openings.
Each game is considered until an heretofore unseen move is encountered. The rest of the game is ignored.
This introduces bias into the dataset but at this point I'm just experimenting.
This increased the speed to ~600 games/sec which is considerable but will likely decrease as the database is populated and more moves are considered per game.
The processing speed is 2 days.

** bongcloud draw
<iframe src="https://lichess.org/embed/game/9EkMS1yG?theme=auto&bg=auto#12"
width=600 height=397 frameborder=0></iframe>
* Going faster
Rust was the obvious choice to do this faster. The first working implementation did the exact same thing but was up to 1700 games/sec unoptimized.
Enabling the =release= profile pushed it up to 17,000 games/sec or 1 hour 40 minutes to process January.

* result of compact vs index comparison
** Compact
#+begin_src sh
❯ cargo run --profile release
   Compiling opening-analyzer v0.1.0 (/hardy/vault/spil/chess/opening-analyzer)
    Finished release [optimized] target(s) in 0.72s
     Running `target/release/opening-analyzer`
reading ../lichess-database/lichess_db_standard_rated_2023-02.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2023-01.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-12.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-11.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-10.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-09.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-08.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-07.pgn.zst
100%|██████████████████████████████████████████████████████| 32000000/32000000 [01:20<00:00, 398524.49it/s]
dbflush
bytes flushed 46458674
size of database file is 5630881134 or 5630.9 MB
Scaled to the whole database, it will be 740.078 GB
parsing 32000000 games at 392476 games/s
parsing took 81.534 seconds
Scaled to the whole database, it will be 10716.142 seconds
main took 81.534 seconds
#+end_src
** Index
#+begin_src sh
❯ cargo run --profile release
   Compiling opening-analyzer v0.1.0 (/hardy/vault/spil/chess/opening-analyzer)
    Finished release [optimized] target(s) in 0.70s
     Running `target/release/opening-analyzer`
reading ../lichess-database/lichess_db_standard_rated_2023-02.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2023-01.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-12.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-11.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-10.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-09.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-08.pgn.zst
reading ../lichess-database/lichess_db_standard_rated_2022-07.pgn.zst
100%|██████████████████████████████████████████████████████| 32000000/32000000 [00:43<00:00, 739076.50it/s]
dbflush
bytes flushed 447441
size of database file is 2642154671 or 2642.2 MB
Scaled to the whole database, it will be 347.264 GB
parsing 32000000 games at 736638 games/s
parsing took 43.441 seconds
Scaled to the whole database, it will be 5709.486 seconds
main took 43.441 seconds
#+end_src
